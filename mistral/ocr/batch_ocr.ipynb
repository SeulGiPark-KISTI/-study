{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahC1s4OldYyM"
      },
      "source": [
        "# OCR Cookbook\n",
        "\n",
        "---\n",
        "\n",
        "## Apply OCR to Convert Images into Text\n",
        "\n",
        "Optical Character Recognition (OCR) allows you to retrieve text data from images. With Mistral OCR, you can do this extremely fast and effectively, extracting text from hundreds and thousands of images (or PDFs).\n",
        "\n",
        "In this simple cookbook, we will extract text from a set of images using two methods:\n",
        "- [Without Batch Inference](#scrollTo=qmXyB3rPlXQW): Looping through the dataset, extracting text from each image, and saving the result.\n",
        "- [With Batch Inference](#scrollTo=jYfWYjzTmixB): Leveraging Batch Inference to extract text with a 50% cost reduction.\n",
        "\n",
        "---\n",
        "\n",
        "### Used\n",
        "\n",
        "- OCR\n",
        "- Batch Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf84okJJmm7M"
      },
      "source": [
        "### Setup\n",
        "First, let's install `mistralai` and `datasets`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X1EBW_a6gRUD",
        "outputId": "78d30e5e-8e09-404c-9230-fd130cbc4a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-1.6.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.8.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (2.33.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.6.0-py3-none-any.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, eval-type-backport, dill, multiprocess, mistralai, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 eval-type-backport-0.2.2 fsspec-2024.12.0 mistralai-1.6.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mistralai datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTpiGWkpmvSb"
      },
      "source": [
        "We can now set up our client. You can create an API key on our [Plateforme](https://console.mistral.ai/api-keys/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwG2kwfTlbW1"
      },
      "outputs": [],
      "source": [
        "from mistralai import Mistral\n",
        "\n",
        "api_key = \"API_KEY\"\n",
        "client = Mistral(api_key=api_key)\n",
        "ocr_model = \"mistral-ocr-latest\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmXyB3rPlXQW"
      },
      "source": [
        "## Without Batch\n",
        "\n",
        "As an example, let's use Mistral OCR to extract text from multiple images.\n",
        "\n",
        "We will use a dataset containing raw image data. To send this data via an image URL, we need to encode it in base64. For more information, please visit our [Vision Documentation](https://docs.mistral.ai/capabilities/vision/#passing-a-base64-encoded-image)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNo8DZ7WbaBq"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "def encode_image_data(image_data):\n",
        "    try:\n",
        "        # Ensure image_data is bytes\n",
        "        if isinstance(image_data, bytes):\n",
        "            # Directly encode bytes to base64\n",
        "            return base64.b64encode(image_data).decode('utf-8')\n",
        "        else:\n",
        "            # Convert image data to bytes if it's not already\n",
        "            buffered = BytesIO()\n",
        "            image_data.save(buffered, format=\"JPEG\")\n",
        "            return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "    except Exception as e:\n",
        "        print(f\"Error encoding image: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m7d2yBImCfO"
      },
      "source": [
        "For this demo, we will use a simple dataset containing numerous documents and scans in image format. Specifically, we will use the `HuggingFaceM4/DocumentVQA` dataset, loaded via the `datasets` library.\n",
        "\n",
        "We will download only 100 samples for this demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ55QEifcgUq"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "n_samples = 100\n",
        "dataset = load_dataset(\"HuggingFaceM4/DocumentVQA\", split=\"train\", streaming=True)\n",
        "subset = list(dataset.take(n_samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TEAOOVUmVNu"
      },
      "source": [
        "With our subset of 100 samples ready, we can loop through each image to extract the text.\n",
        "\n",
        "We will save the results in a new dataset and export it as a JSONL file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOUGkkrfce63",
        "outputId": "58510dc0-8191-4ad6-fea4-b005f5198926"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [02:13<00:00,  1.33s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "ocr_dataset = []\n",
        "for sample in tqdm(subset):\n",
        "    image_data = sample['image']  # 'image' contains the actual image data\n",
        "\n",
        "    # Encode the image data to base64\n",
        "    base64_image = encode_image_data(image_data)\n",
        "    image_url = f\"data:image/jpeg;base64,{base64_image}\"\n",
        "\n",
        "    # Process the image using Mistral OCR\n",
        "    response = client.ocr.process(\n",
        "        model=ocr_model,\n",
        "        document={\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": image_url,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Store the image data and OCR content in the new dataset\n",
        "    ocr_dataset.append({\n",
        "        'image': base64_image,\n",
        "        'ocr_content': response.pages[0].markdown # Since we are dealing with single images, there will be only one page\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bcncJL0dAFk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('ocr_dataset.json', 'w') as f:\n",
        "    json.dump(ocr_dataset, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYfWYjzTmixB"
      },
      "source": [
        "Perfect, we have extracted all text from the 100 samples. However, this process can be made more cost-efficient using Batch Inference.\n",
        "\n",
        "## With Batch\n",
        "\n",
        "To use Batch Inference, we need to create a JSONL file containing all the image data and request information for our batch.\n",
        "\n",
        "Let's create a function called `create_batch_file` to handle this task by generating a file in the proper format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHKPWyqVhFn_"
      },
      "outputs": [],
      "source": [
        "def create_batch_file(image_urls, output_file):\n",
        "    with open(output_file, 'w') as file:\n",
        "        for index, url in enumerate(image_urls):\n",
        "            entry = {\n",
        "                \"custom_id\": str(index),\n",
        "                \"body\": {\n",
        "                    \"document\": {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": url\n",
        "                    },\n",
        "                    \"include_image_base64\": True\n",
        "                }\n",
        "            }\n",
        "            file.write(json.dumps(entry) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gmWu5dGm79P"
      },
      "source": [
        "The next step involves encoding the data of each image into base64 and saving the URL of each image that will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_Fg_t-shHgj",
        "outputId": "8fbe8b03-7d8a-4c13-96b0-98d56a4c4c82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [00:00<00:01, 41.07it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.48it/s]\n"
          ]
        }
      ],
      "source": [
        "image_urls = []\n",
        "for sample in tqdm(subset):\n",
        "    image_data = sample['image']  # 'image' contains the actual image data\n",
        "\n",
        "    # Encode the image data to base64 and add the url to the list\n",
        "    base64_image = encode_image_data(image_data)\n",
        "    image_url = f\"data:image/jpeg;base64,{base64_image}\"\n",
        "    image_urls.append(image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6q1JR73nIhe"
      },
      "source": [
        "We can now create our batch file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A3cRUP0gf6W"
      },
      "outputs": [],
      "source": [
        "batch_file = \"batch_file.jsonl\"\n",
        "create_batch_file(image_urls, batch_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4ME_pJCnM6-"
      },
      "source": [
        "With everything ready, we can upload it to the API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGBd3kRfgnyq"
      },
      "outputs": [],
      "source": [
        "batch_data = client.files.upload(\n",
        "    file={\n",
        "        \"file_name\": batch_file,\n",
        "        \"content\": open(batch_file, \"rb\")},\n",
        "    purpose = \"batch\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q7dpJ07nVOO"
      },
      "source": [
        "The file is uploaded, but the batch inference has not started yet. To initiate it, we need to create a job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2iBH3Ikgzb7"
      },
      "outputs": [],
      "source": [
        "created_job = client.batch.jobs.create(\n",
        "    input_files=[batch_data.id],\n",
        "    model=ocr_model,\n",
        "    endpoint=\"/v1/ocr\",\n",
        "    metadata={\"job_type\": \"testing\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE_DBRu4nbXz"
      },
      "source": [
        "Our batch is ready and running!\n",
        "\n",
        "We can retrieve information using the following method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dIph-xtg94n",
        "outputId": "cf8adcc4-310c-435f-eab0-7fd2c706d4b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status: QUEUED\n",
            "Total requests: 100\n",
            "Failed requests: 0\n",
            "Successful requests: 0\n",
            "Percent done: 0.0%\n"
          ]
        }
      ],
      "source": [
        "retrieved_job = client.batch.jobs.get(job_id=created_job.id)\n",
        "print(f\"Status: {retrieved_job.status}\")\n",
        "print(f\"Total requests: {retrieved_job.total_requests}\")\n",
        "print(f\"Failed requests: {retrieved_job.failed_requests}\")\n",
        "print(f\"Successful requests: {retrieved_job.succeeded_requests}\")\n",
        "print(\n",
        "    f\"Percent done: {round((retrieved_job.succeeded_requests + retrieved_job.failed_requests) / retrieved_job.total_requests, 4) * 100}%\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWMupK2Sng-5"
      },
      "source": [
        "Let's automate this feedback loop and download the results once they are ready!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oarRyxv4jV6B",
        "outputId": "1639a6a0-8a3a-450e-e11e-da9974cdded0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status: SUCCESS\n",
            "Total requests: 100\n",
            "Failed requests: 0\n",
            "Successful requests: 100\n",
            "Percent done: 100.0%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "while retrieved_job.status in [\"QUEUED\", \"RUNNING\"]:\n",
        "    retrieved_job = client.batch.jobs.get(job_id=created_job.id)\n",
        "\n",
        "    clear_output(wait=True)  # Clear the previous output ( User Friendly )\n",
        "    print(f\"Status: {retrieved_job.status}\")\n",
        "    print(f\"Total requests: {retrieved_job.total_requests}\")\n",
        "    print(f\"Failed requests: {retrieved_job.failed_requests}\")\n",
        "    print(f\"Successful requests: {retrieved_job.succeeded_requests}\")\n",
        "    print(\n",
        "        f\"Percent done: {round((retrieved_job.succeeded_requests + retrieved_job.failed_requests) / retrieved_job.total_requests, 4) * 100}%\"\n",
        "    )\n",
        "    time.sleep(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKH-dYmxhBjX",
        "outputId": "36f505eb-e04e-45fe-cee4-abb9e3e24433"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [200 OK]>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.files.download(file_id=retrieved_job.output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGyDanavnq0C"
      },
      "source": [
        "Done! With this method, you can perform OCR tasks in bulk in a very cost-effective way."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}